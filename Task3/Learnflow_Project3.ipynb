{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Natural Language Processing (NLP) for Sentiment Analysis\n",
        "\n",
        "###Problem Statement:\n",
        "Build a sentiment analysis model using NLP techniques. The goal is to classify text reviews\n",
        "as positive, negative, or neutral. Use a dataset like the IMDb Movie Reviews dataset.\n"
      ],
      "metadata": {
        "id": "eY8VL7w-WKwi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **Objective:**\n",
        "   - The primary objective is to develop a model for sentiment analysis, a task within NLP. Sentiment analysis involves determining the sentiment expressed in a piece of text, such as positive, negative, or neutral.\n",
        "\n",
        "2. **NLP Techniques:**\n",
        "   - Natural Language Processing involves the use of computational methods to understand and process human language. In this context, NLP techniques are employed to analyze and interpret text data, particularly for sentiment classification.\n",
        "\n",
        "3. **Dataset:**\n",
        "   - The dataset mentioned for training is the IMDb Movie Reviews dataset. This dataset likely contains movie reviews along with their corresponding sentiment labels (positive, negative, or neutral).\n",
        "\n",
        "4. **Sentiment Analysis:**\n",
        "   - Sentiment analysis, also known as opinion mining, is a task in NLP that involves determining the sentiment expressed in a piece of text. It is often used to automatically classify text as positive, negative, or neutral based on the emotions or opinions conveyed.\n",
        "\n",
        "5. **Input Data:**\n",
        "   - The input data for this problem consists of text reviews, specifically movie reviews from the IMDb dataset. Each review is associated with a sentiment label, indicating whether it is positive, negative, or neutral.\n",
        "\n",
        "6. **Model Development:**\n",
        "   - The model needs to be designed to analyze the text and predict the sentiment. Techniques such as word embeddings (e.g., Word2Vec, GloVe) and recurrent neural networks (RNNs) or transformer models (e.g., BERT) are commonly used for sentiment analysis tasks.\n",
        "\n",
        "7. **Training:**\n",
        "   - The model is trained on the IMDb Movie Reviews dataset. During training, the model learns to map the input text reviews to their corresponding sentiment labels. The model's parameters are adjusted to minimize the difference between predicted and actual sentiments.\n",
        "\n",
        "8. **Evaluation:**\n",
        "   - The performance of the sentiment analysis model is evaluated on a separate dataset, often a test set from the IMDb Movie Reviews dataset. Common evaluation metrics include accuracy, precision, recall, and F1 score.\n",
        "\n",
        "9. **Application:**\n",
        "   - Once the model is trained and validated, it can be used to classify the sentiment of new text reviews. This has practical applications in industries such as e-commerce, social media monitoring, and customer feedback analysis, where automated sentiment analysis can provide valuable insights."
      ],
      "metadata": {
        "id": "wIZn6jI3cQYW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Generating Data"
      ],
      "metadata": {
        "id": "FwVMFx2Xl7XP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.models import load_model\n",
        "import re\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FBc3QBW7NSDa",
        "outputId": "f76eef63-5244-47cc-e304-fe16e97e9814"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "data = pd.read_csv('/content/drive/MyDrive/dataset/IMDB-Dataset.csv')"
      ],
      "metadata": {
        "id": "VyUdx7pdNSHY"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zAOUbHvHNSPp",
        "outputId": "b835206f-885b-40c0-bc2d-8a64b298bec7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                  review sentiment\n",
            "0      One of the other reviewers has mentioned that ...  positive\n",
            "1      A wonderful little production. <br /><br />The...  positive\n",
            "2      I thought this was a wonderful way to spend ti...  positive\n",
            "3      Basically there's a family where a little boy ...  negative\n",
            "4      Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
            "...                                                  ...       ...\n",
            "49995  I thought this movie did a down right good job...  positive\n",
            "49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative\n",
            "49997  I am a Catholic taught in parochial elementary...  negative\n",
            "49998  I'm going to have to disagree with the previou...  negative\n",
            "49999  No one expects the Star Trek movies to be high...  negative\n",
            "\n",
            "[50000 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "english_stop_words = set(stopwords.words('english'))"
      ],
      "metadata": {
        "id": "k7mZVfw3NSRn"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dataset():\n",
        "    df = pd.read_csv('/content/drive/MyDrive/dataset/IMDB-Dataset.csv')\n",
        "    x_data = df['review']       # Reviews/Input\n",
        "    y_data = df['sentiment']    # Sentiment/Output\n",
        "\n",
        "    # Pre-process review\n",
        "    x_data = x_data.replace({'<.*?>': ''}, regex=True)          # remove html tag\n",
        "    x_data = x_data.replace({'[^A-Za-z]': ' '}, regex=True)     # remove non-alphabet\n",
        "    x_data = x_data.apply(lambda review: [w for w in review.split() if w not in english_stop_words])  # remove stop words\n",
        "    x_data = x_data.apply(lambda review: [w.lower() for w in review])   # lower case\n",
        "\n",
        "    # Encode sentiment -> 0 & 1\n",
        "    y_data = y_data.replace('positive', 1)\n",
        "    y_data = y_data.replace('negative', 0)\n",
        "\n",
        "    return x_data, y_data"
      ],
      "metadata": {
        "id": "HWutK6Q_NSTu"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_data, y_data = load_dataset()"
      ],
      "metadata": {
        "id": "T7jU8bk0NSXi"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Reviews')\n",
        "print(x_data, '\\n')\n",
        "print('Sentiment')\n",
        "print(y_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CipG4QNqNSZe",
        "outputId": "8b4f53c6-c856-4f36-ee72-950a469f4a08"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reviews\n",
            "0        [one, reviewers, mentioned, watching, oz, epis...\n",
            "1        [a, wonderful, little, production, the, filmin...\n",
            "2        [i, thought, wonderful, way, spend, time, hot,...\n",
            "3        [basically, family, little, boy, jake, thinks,...\n",
            "4        [petter, mattei, love, time, money, visually, ...\n",
            "                               ...                        \n",
            "49995    [i, thought, movie, right, good, job, it, crea...\n",
            "49996    [bad, plot, bad, dialogue, bad, acting, idioti...\n",
            "49997    [i, catholic, taught, parochial, elementary, s...\n",
            "49998    [i, going, disagree, previous, comment, side, ...\n",
            "49999    [no, one, expects, star, trek, movies, high, a...\n",
            "Name: review, Length: 50000, dtype: object \n",
            "\n",
            "Sentiment\n",
            "0        1\n",
            "1        1\n",
            "2        1\n",
            "3        0\n",
            "4        1\n",
            "        ..\n",
            "49995    1\n",
            "49996    0\n",
            "49997    0\n",
            "49998    0\n",
            "49999    0\n",
            "Name: sentiment, Length: 50000, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.3)"
      ],
      "metadata": {
        "id": "EyaOnMehNSbZ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Train Set')\n",
        "print(x_train, '\\n')\n",
        "print(x_test, '\\n')\n",
        "print('Test Set')\n",
        "print(y_train, '\\n')\n",
        "print(y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8WSgveoNSdW",
        "outputId": "26bb96f2-c3aa-4781-dcce-ff24c196a81e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Set\n",
            "28704    [if, like, occasionally, enjoy, watching, terr...\n",
            "9562     [less, thriller, colorful, adventure, suspense...\n",
            "27943    [for, big, thinkers, among, us, the, intruder,...\n",
            "35643    [a, wounded, tonto, standing, alone, protect, ...\n",
            "42738    [it, utterly, pointless, rate, film, it, would...\n",
            "                               ...                        \n",
            "8108     [blake, edwards, legendary, fiasco, begins, se...\n",
            "29517    [a, young, solicitor, london, arthur, kidd, se...\n",
            "9914     [the, german, regional, broadcast, station, wd...\n",
            "28110    [yeesh, talk, craptastic, thing, brutal, horri...\n",
            "21269    [the, book, movie, based, excellent, took, com...\n",
            "Name: review, Length: 35000, dtype: object \n",
            "\n",
            "47555    [a, film, little, positive, say, firstly, zero...\n",
            "39692    [i, read, almost, books, seen, musical, produc...\n",
            "5475     [naach, a, detailed, review, obtained, anywher...\n",
            "27621    [when, watching, show, quite, sure, whether, s...\n",
            "44154    [this, film, worst, film, i, ever, seen, it, c...\n",
            "                               ...                        \n",
            "41462    [of, course, going, one, would, expect, typica...\n",
            "4572     [eric, phillips, don, wilson, secret, service,...\n",
            "34088    [paul, mazursky, misfires, film, the, writing,...\n",
            "13357    [this, much, sort, movie, john, wayne, known, ...\n",
            "23972    [the, combination, dan, haggerty, elves, linda...\n",
            "Name: review, Length: 15000, dtype: object \n",
            "\n",
            "Test Set\n",
            "28704    0\n",
            "9562     1\n",
            "27943    0\n",
            "35643    1\n",
            "42738    1\n",
            "        ..\n",
            "8108     0\n",
            "29517    1\n",
            "9914     0\n",
            "28110    0\n",
            "21269    1\n",
            "Name: sentiment, Length: 35000, dtype: int64 \n",
            "\n",
            "47555    0\n",
            "39692    0\n",
            "5475     0\n",
            "27621    0\n",
            "44154    0\n",
            "        ..\n",
            "41462    1\n",
            "4572     0\n",
            "34088    0\n",
            "13357    1\n",
            "23972    0\n",
            "Name: sentiment, Length: 15000, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_max_length():\n",
        "    review_length = [len(review) for review in x_train]\n",
        "    return int(np.ceil(np.mean(review_length)))"
      ],
      "metadata": {
        "id": "h0m9YKNbNSfO"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode review\n",
        "tokenizer = Tokenizer(lower=False)    # no need lower, because already lowered the data in load_data()\n",
        "tokenizer.fit_on_texts(x_train)\n",
        "x_train = tokenizer.texts_to_sequences(x_train)\n",
        "x_test = tokenizer.texts_to_sequences(x_test)\n",
        "\n",
        "max_length = get_max_length()\n",
        "\n",
        "x_train = pad_sequences(x_train, maxlen=max_length, padding='post', truncating='post')\n",
        "x_test = pad_sequences(x_test, maxlen=max_length, padding='post', truncating='post')\n",
        "\n",
        "total_words = len(tokenizer.word_index) + 1   # add 1 because of 0 padding\n",
        "\n",
        "print('Encoded X Train\\n', x_train, '\\n')\n",
        "print('Encoded X Test\\n', x_test, '\\n')\n",
        "print('Maximum review length: ', max_length)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UFxD4zWkNShI",
        "outputId": "a910fe31-0fb3-4725-972b-a1f6bd508665"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoded X Train\n",
            " [[   55     6  1798 ...     0     0     0]\n",
            " [  244   615  3169 ...   308  1701   163]\n",
            " [  202   103 18170 ...     0     0     0]\n",
            " ...\n",
            " [    2   925 14836 ...     0     0     0]\n",
            " [41658   600 29090 ...     0     0     0]\n",
            " [    2   174     3 ...     0     0     0]] \n",
            "\n",
            "Encoded X Test\n",
            " [[   40     4    48 ...  2011  4148   165]\n",
            " [    1   245   120 ...  1598  2818 18028]\n",
            " [46426    40  3637 ...   107    83     8]\n",
            " ...\n",
            " [  692 19491 22209 ...     0     0     0]\n",
            " [    8    17   344 ...   132    16   317]\n",
            " [    2  2148  1991 ... 10555    50  1362]] \n",
            "\n",
            "Maximum review length:  130\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Architecture\n",
        "EMBED_DIM = 32\n",
        "LSTM_OUT = 64\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(total_words, EMBED_DIM, input_length=max_length))\n",
        "model.add(LSTM(LSTM_OUT))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "print(model.summary())\n",
        "\n",
        "checkpoint = ModelCheckpoint(\n",
        "    'models/LSTM.h5',\n",
        "    monitor='accuracy',\n",
        "    save_best_only=True,\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DS1MMVOIN3L0",
        "outputId": "53a1edd2-169e-4063-d443-d92f19c571de"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_2 (Embedding)     (None, 130, 32)           2804480   \n",
            "                                                                 \n",
            " lstm_2 (LSTM)               (None, 64)                24832     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2829377 (10.79 MB)\n",
            "Trainable params: 2829377 (10.79 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Architecture\n",
        "EMBED_DIM = 32\n",
        "LSTM_OUT = 64\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(total_words, EMBED_DIM, input_length=max_length))\n",
        "model.add(LSTM(LSTM_OUT))\n",
        "model.add(Dense(1, activation='relu'))\n",
        "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])\n",
        "\n",
        "print(model.summary())\n",
        "\n",
        "checkpoint = ModelCheckpoint(\n",
        "    'models/RAB.h5',\n",
        "    monitor='accuracy',\n",
        "    save_best_only=True,\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QKqyNXpFRXMg",
        "outputId": "ed83a699-d51b-4892-a782-dcffc6f2dbc9"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_5 (Embedding)     (None, 130, 32)           2804480   \n",
            "                                                                 \n",
            " lstm_5 (LSTM)               (None, 64)                24832     \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2829377 (10.79 MB)\n",
            "Trainable params: 2829377 (10.79 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x_train, y_train, batch_size=128, epochs=5, callbacks=[checkpoint])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XHCHf_fQN6nt",
        "outputId": "ff71b74a-5888-44c1-f671-92ff083a4020"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "274/274 [==============================] - ETA: 0s - loss: 0.2005 - accuracy: 0.6617\n",
            "Epoch 1: accuracy improved from -inf to 0.66166, saving model to models/RAB.h5\n",
            "274/274 [==============================] - 65s 229ms/step - loss: 0.2005 - accuracy: 0.6617\n",
            "Epoch 2/5\n",
            "274/274 [==============================] - ETA: 0s - loss: 0.0696 - accuracy: 0.9115\n",
            "Epoch 2: accuracy improved from 0.66166 to 0.91154, saving model to models/RAB.h5\n",
            "274/274 [==============================] - 62s 226ms/step - loss: 0.0696 - accuracy: 0.9115\n",
            "Epoch 3/5\n",
            "274/274 [==============================] - ETA: 0s - loss: 0.0371 - accuracy: 0.9561\n",
            "Epoch 3: accuracy improved from 0.91154 to 0.95606, saving model to models/RAB.h5\n",
            "274/274 [==============================] - 61s 223ms/step - loss: 0.0371 - accuracy: 0.9561\n",
            "Epoch 4/5\n",
            "274/274 [==============================] - ETA: 0s - loss: 0.0237 - accuracy: 0.9737\n",
            "Epoch 4: accuracy improved from 0.95606 to 0.97366, saving model to models/RAB.h5\n",
            "274/274 [==============================] - 62s 227ms/step - loss: 0.0237 - accuracy: 0.9737\n",
            "Epoch 5/5\n",
            "274/274 [==============================] - ETA: 0s - loss: 0.0211 - accuracy: 0.9774\n",
            "Epoch 5: accuracy improved from 0.97366 to 0.97740, saving model to models/RAB.h5\n",
            "274/274 [==============================] - 62s 228ms/step - loss: 0.0211 - accuracy: 0.9774\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7c2aa52cceb0>"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_probs = model.predict(x_test, batch_size=128)\n",
        "y_pred_classes = (y_pred_probs > 0.5).astype(int)\n",
        "\n",
        "true = sum(1 for i, y in enumerate(y_test) if y == y_pred_classes[i])\n",
        "\n",
        "print('Correct Prediction: {}'.format(true))\n",
        "print('Wrong Prediction: {}'.format(len(y_pred_classes) - true))\n",
        "print('Accuracy: {:.2%}'.format(true / len(y_pred_classes)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CqUXGZvIQFq3",
        "outputId": "e3a1d3f4-0e46-4310-ce59-82e864e53bf7"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "118/118 [==============================] - 10s 84ms/step\n",
            "Correct Prediction: 13054\n",
            "Wrong Prediction: 1946\n",
            "Accuracy: 87.03%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model = load_model('models/RAB.h5')"
      ],
      "metadata": {
        "id": "ehCpwi-eOA36"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_review = str(input('Movie Review: '))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PX-zYskCOA2B",
        "outputId": "69c8170d-ffce-469a-8216-7f91d277db62"
      },
      "execution_count": 86,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Movie Review: 7.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pre-process input\n",
        "regex = re.compile(r'[^a-zA-Z\\s]')\n",
        "user_review = regex.sub('', user_review)\n",
        "print('Cleaned: ', user_review)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z4xI2qvjOAz5",
        "outputId": "ac0fff10-6ccf-4e60-f474-365753df7c9d"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaned:  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words = user_review.split(' ')\n",
        "filtered = [w for w in words if w not in english_stop_words]\n",
        "filtered = ' '.join(filtered)\n",
        "filtered = [filtered.lower()]\n",
        "\n",
        "print('Filtered: ', filtered)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4gio1aueOP2T",
        "outputId": "4ac279ca-4efe-43a5-f55e-751472611ba6"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filtered:  ['']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_words = tokenizer.texts_to_sequences(filtered)\n",
        "tokenized_words = pad_sequences(tokenized_words, maxlen=max_length, padding='post', truncating='post')\n",
        "print(tokenized_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5WOv0rBOP0b",
        "outputId": "de9259f5-4cfb-437a-fff6-bd9170503d98"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = loaded_model.predict(tokenized_words)\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d7HXEzpNOPyf",
        "outputId": "72a35635-3575-4992-fcf2-ad5ada5cc106"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 31ms/step\n",
            "[[0.9254229]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if result >= 0.7:\n",
        "    print('positive')\n",
        "else:\n",
        "    print('negative')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hWv_GZz-OPwU",
        "outputId": "efcec4a4-f1bd-4ea4-b6f2-a9d61cf21f05"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "positive\n"
          ]
        }
      ]
    }
  ]
}